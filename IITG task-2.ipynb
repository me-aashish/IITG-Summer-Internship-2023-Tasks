{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecb4bad9",
   "metadata": {},
   "source": [
    "### [5 Marks] Briefly explain and implement from scratch the following functions: i) cross-entropy; ii) entropy; iii) mutual information; iv) conditional entropy; v) KL divergence. Take appropriate example toy data/distributions and explain the insights from calculating these quantities.\n",
    "\n",
    "###### (here functions are not explained serial wise in order to give better explanation and understanding of the functions sequentially)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51aff1a",
   "metadata": {},
   "source": [
    "#### importing useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798bc19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e2603eff",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51d9c87c",
   "metadata": {},
   "source": [
    "#### importing breast_cancer toy dataset from sklearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c6f221a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#loading the breast cancer data \n",
    "breast_cancer_data = load_breast_cancer() \n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94d5d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    " #X will contain all the input variable\n",
    "X = breast_cancer_data.data\n",
    "\n",
    "#here y is the target variable containing values 0 & 1; \n",
    "#0 meaning no breat cancer while 1 means there is breast cancer\n",
    "y = breast_cancer_data.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7cf4b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "0                   0.07871  ...        25.380          17.33   \n",
       "1                   0.05667  ...        24.990          23.41   \n",
       "2                   0.05999  ...        23.570          25.53   \n",
       "3                   0.09744  ...        14.910          26.50   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "..                      ...  ...           ...            ...   \n",
       "564                 0.05623  ...        25.450          26.40   \n",
       "565                 0.05533  ...        23.690          38.25   \n",
       "566                 0.05648  ...        18.980          34.12   \n",
       "567                 0.07016  ...        25.740          39.42   \n",
       "568                 0.05884  ...         9.456          30.37   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "0             184.60      2019.0           0.16220            0.66560   \n",
       "1             158.80      1956.0           0.12380            0.18660   \n",
       "2             152.50      1709.0           0.14440            0.42450   \n",
       "3              98.87       567.7           0.20980            0.86630   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "..               ...         ...               ...                ...   \n",
       "564           166.10      2027.0           0.14100            0.21130   \n",
       "565           155.00      1731.0           0.11660            0.19220   \n",
       "566           126.70      1124.0           0.11390            0.30940   \n",
       "567           184.60      1821.0           0.16500            0.86810   \n",
       "568            59.16       268.6           0.08996            0.06444   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "0             0.7119                0.2654          0.4601   \n",
       "1             0.2416                0.1860          0.2750   \n",
       "2             0.4504                0.2430          0.3613   \n",
       "3             0.6869                0.2575          0.6638   \n",
       "4             0.4000                0.1625          0.2364   \n",
       "..               ...                   ...             ...   \n",
       "564           0.4107                0.2216          0.2060   \n",
       "565           0.3215                0.1628          0.2572   \n",
       "566           0.3403                0.1418          0.2218   \n",
       "567           0.9387                0.2650          0.4087   \n",
       "568           0.0000                0.0000          0.2871   \n",
       "\n",
       "     worst fractal dimension  \n",
       "0                    0.11890  \n",
       "1                    0.08902  \n",
       "2                    0.08758  \n",
       "3                    0.17300  \n",
       "4                    0.07678  \n",
       "..                       ...  \n",
       "564                  0.07115  \n",
       "565                  0.06637  \n",
       "566                  0.07820  \n",
       "567                  0.12400  \n",
       "568                  0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's take overview of all the input variables \n",
    "df_inputs = pd.DataFrame(data = X, columns = breast_cancer_data.feature_names)\n",
    "df_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f83bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   mean radius              569 non-null    float64\n",
      " 1   mean texture             569 non-null    float64\n",
      " 2   mean perimeter           569 non-null    float64\n",
      " 3   mean area                569 non-null    float64\n",
      " 4   mean smoothness          569 non-null    float64\n",
      " 5   mean compactness         569 non-null    float64\n",
      " 6   mean concavity           569 non-null    float64\n",
      " 7   mean concave points      569 non-null    float64\n",
      " 8   mean symmetry            569 non-null    float64\n",
      " 9   mean fractal dimension   569 non-null    float64\n",
      " 10  radius error             569 non-null    float64\n",
      " 11  texture error            569 non-null    float64\n",
      " 12  perimeter error          569 non-null    float64\n",
      " 13  area error               569 non-null    float64\n",
      " 14  smoothness error         569 non-null    float64\n",
      " 15  compactness error        569 non-null    float64\n",
      " 16  concavity error          569 non-null    float64\n",
      " 17  concave points error     569 non-null    float64\n",
      " 18  symmetry error           569 non-null    float64\n",
      " 19  fractal dimension error  569 non-null    float64\n",
      " 20  worst radius             569 non-null    float64\n",
      " 21  worst texture            569 non-null    float64\n",
      " 22  worst perimeter          569 non-null    float64\n",
      " 23  worst area               569 non-null    float64\n",
      " 24  worst smoothness         569 non-null    float64\n",
      " 25  worst compactness        569 non-null    float64\n",
      " 26  worst concavity          569 non-null    float64\n",
      " 27  worst concave points     569 non-null    float64\n",
      " 28  worst symmetry           569 non-null    float64\n",
      " 29  worst fractal dimension  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    " #getting info about the input variables\n",
    "df_inputs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02317c8c",
   "metadata": {},
   "source": [
    "we can see that there is not any null value in input variable X.\n",
    "let's check the target variable"
   ]
  },
  {
   "cell_type": "raw",
   "id": "331e4173",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24f4dae0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#overviewing target variable\n",
    "df_target = pd.DataFrame(data=y)\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99c485fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   0       569 non-null    int32\n",
      "dtypes: int32(1)\n",
      "memory usage: 2.3 KB\n"
     ]
    }
   ],
   "source": [
    "##getting info about the target variable\n",
    "df_target.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38ecbf5",
   "metadata": {},
   "source": [
    "we can see that there is not any null value in target variable y too."
   ]
  },
  {
   "cell_type": "raw",
   "id": "1b922cda",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "993ab345",
   "metadata": {},
   "source": [
    "### Now, let's implement our functions from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72df27ea",
   "metadata": {},
   "source": [
    "#### ii) Entropy\n",
    "Entropy is a measure of the amount of uncertainty or randomness in a system. In the context of machine learning, entropy is commonly used as a criterion for evaluating the purity of a split in a decision tree algorithm.\n",
    "\n",
    "Also, according to Shannon’s information theory, entropy measures the average information content of a message: entropy is zero when all messages are identical. In Machine Learning, it is frequently used as an impurity measure.\n",
    "\n",
    "The entropy or entropy of a node in decision tree is defined as:\n",
    "<span style=\"color:blue\">$$ E = -\\sum p(i)log_{2}p(i) $$</span>\n",
    "where: p(i) is the probability of the i-th class in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eaa4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy is : 0.9526351224018599\n"
     ]
    }
   ],
   "source": [
    "#let's define function for entropy from scratch\n",
    "def entropy(Y): #here, we will be calculating entropy of data present in Y\n",
    "    unique, count = np.unique(Y, return_counts=True, axis=0)\n",
    "    \n",
    "    #calculating probability\n",
    "    prob = count/len(Y)\n",
    "    \n",
    "    #applying formula\n",
    "    ent = -np.sum(np.dot(prob,np.log2(prob)))\n",
    "    return ent\n",
    "\n",
    "#now, let's find the entropy of target variable y\n",
    "print(\"Entropy is:\",entropy(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0a7365",
   "metadata": {},
   "source": [
    "So here, we can see that the the entropy of target variable \"y\" is 0.95 which is the amount of information contained by \"y\"."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb45109e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eafb1861",
   "metadata": {},
   "source": [
    "#### iv) Conditional Entropy\n",
    "In machine learning, conditional entropy is a measure of the uncertainty of a random variable X given the value of another random variable Y.\n",
    "\n",
    "Also, it can also be defined as - conditional entropy(Y,X) = Joint Entropy(Y,X) - Entropy of X as:<span style=\"color:blue\">$$H(Y|X) = H(Y;X) - H(X)  $$ </span>where H(Y|X) is Conditional Entropy of Y given X, H(Y;X) is Joint Entropy of Y and X, H(X) is Entropy of X and Y,X being any two random variable.\n",
    "\n",
    "So, let's discuss about joint entropy - In machine learning, joint entropy is a measure of the uncertainty of a pair of random variables. Specifically, joint entropy measures the amount of information contained in both random variables together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b38ab26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conditional Entropy is :  0.3282846880834285\n"
     ]
    }
   ],
   "source": [
    "#Joint Entropy\n",
    "def joint_entropy(Y,X):\n",
    "    YX = np.c_[Y,X]  #concatinating both Y and X\n",
    "    return entropy(YX)\n",
    "\n",
    "#Conditional Entropy\n",
    "def conditional_entropy(Y, X):\n",
    "    return joint_entropy(Y, X) - entropy(X)\n",
    "\n",
    "#Let's take any two random input variable from X and find their conditional entropy\n",
    "#Let x1 be mean radius(first row of X) and x2 be mean texture(second row of X)\n",
    "x1 = df_inputs[\"mean radius\"]\n",
    "x2 = df_inputs[\"mean texture\"]\n",
    "\n",
    "#converting x1 and x2 into numpy arrays\n",
    "x1 = x1.values\n",
    "x2 = x2.values\n",
    "\n",
    "#finding conditional entropy of variable x1 given the value of x2\n",
    "print(\"Conditional Entropy is: \",conditional_entropy(x1,x2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476a9148",
   "metadata": {},
   "source": [
    "Here, conditional entropy of variable x1 given value of x2 comes out to be 0.32 which shows the measures the amount of uncertainty or randomness in x1(mean radius) after taking into account the information provided by x2(mean texture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d74d71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4289ecd9",
   "metadata": {},
   "source": [
    "#### iii) Mutual Information\n",
    "Mutual information can be defined measure of the dependence between two random variables, often used in machine learning to evaluate feature selection and feature importance.\n",
    "\n",
    "In particular, the mutual information between two random variables X and Y is defined as:\n",
    "<span style=\"color:blue\">$$ I(Y; X) = H(Y) - H(Y|X) $$</span>\n",
    "where I(Y; X) is Mutual Information between Y and X, H(Y) is the Entropy of Y, and H(Y|X) is the Conditional Entropy of Y given X. Intuitively, mutual information measures how much knowing one variable reduces the uncertainty about the other variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b99afaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mutual Information is :  0.8607815854836038\n"
     ]
    }
   ],
   "source": [
    "#mutual information\n",
    "def mutual_info(Y,X):\n",
    "    return (entropy(Y) - conditional_entropy(Y,X))\n",
    "\n",
    "#here, let's find out the mutual information of target \n",
    "#variable y and one of the input variable x1(mean readius)\n",
    "print(\"Mutual Information is: \",mutual_info(y,x1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f93b612",
   "metadata": {},
   "source": [
    "Here, 0.86 is therefore the reduction in uncertainty about target variable y,or the expected reduction in the number of yes/no questions needed to guess y after observing x1(mean radius)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9f1b1352",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b19a22f",
   "metadata": {},
   "source": [
    "#### i) Cross Entropy\n",
    "Cross-entropy, also known as log loss can be defined as a loss function commonly used in machine learning for classification tasks. It measures the dissimilarity between the predicted probability distribution and the true probability distribution of the target variable.\n",
    "\n",
    "In classification tasks, the model outputs a probability distribution over the possible classes for each input instance. The cross-entropy measures how well the predicted probability distribution matches the true probability distribution, which is typically represented as a one-hot encoded vector (i.e., a vector with a single 1 and all other elements 0, indicating the true class of the instance).\n",
    "\n",
    "Formula for cross entropy can be written as:\n",
    "cross entropy = <span style=\"color:blue\">$$ -Σ [p_{i} * log_{2}(q_{i})] $$</span>\n",
    "where i ranges over all possible outcomes, and p_i and q_i are the probabilities of the i-th outcome according to the true distribution and the predicted distribution, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "acff8da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy:  0.5204082855966206\n"
     ]
    }
   ],
   "source": [
    "#cross entropy\n",
    "def cross_entropy(true_probability,predicted_probability):\n",
    "#     return -np.sum(np.where(predicted_probability!=0,np.dot(true_probability,np.log2(predicted_probability)))\n",
    "      return log_loss(true_probability,predicted_probability)\n",
    "\n",
    "# Import necessary libraries\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#creating a model for predicting the probability\n",
    "model = GaussianNB()\n",
    "\n",
    "#fitting the input variables X and target variable \n",
    "#y to the model\n",
    "model.fit(X,y)\n",
    "\n",
    "#predicting probability for input variable X\n",
    "predicted_probability = model.predict_proba(X)[:,1] #since predict_proba() return a 2-D matrix \n",
    "                                                    #of probabilities of 0 and 1 respectively, \n",
    "                                                    #so here I'm slicing it to take the probability\n",
    "                                                    #of either 0 or 1\n",
    "\n",
    "#here y, the target variable is true probability \n",
    "#while we have calulated predicted probability\n",
    "print(\"Cross Entropy: \",cross_entropy(y,predicted_probability))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226a186e",
   "metadata": {},
   "source": [
    "Here, we can see that cross entropy comes out to be 0.52 which represents the logarithmic loss score of the model.The lower the value of cross-entropy, the better the model is at predicting the classes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "43e79071",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e7c6ea",
   "metadata": {},
   "source": [
    "#### v) KL Divergence\n",
    "KL divergence (or Kullback-Leibler divergence) is a measure of dissimilarity between two probability distributions. In machine learning, KL divergence is often used as a loss function or as a measure of performance.\n",
    "\n",
    "Formally, given two probability distributions p and q over the same space, the KL divergence from p to q measures the expected number of extra bits required to code samples from p using a code optimized for q, compared to using a code optimized for p(according to Shannon's Information Theory) . This can be written as:\n",
    "<span style=\"color:blue\">$$ KL(p||q) = \\sum p(x) * log(\\frac{p(x)}{q(x)}) $$ </span>\n",
    "\n",
    "Here, p(x) and q(x) are the probabilities of observing the value x under the distributions p and q, respectively. The KL divergence is asymmetric, meaning KL(p||q) is not equal to KL(q||p), and is also non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9061ce95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL divergence: 0.5341040492226561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python 3.8\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#importing necessary library\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42) #as defined in above cells, X is input variables and y is target variable\n",
    "\n",
    "# Compute the true distribution of the labels\n",
    "p = np.bincount(y_train) / len(y_train)\n",
    "\n",
    "#Define a function to compute the predicted \n",
    "#distribution of the labels\n",
    "def get_predicted_distribution(X, y, model):\n",
    "    \n",
    "    # Compute the predicted probabilities of the positive class\n",
    "    y_pred_prob = model.predict_proba(X)[:, 1]\n",
    "    \n",
    "    # Compute the predicted distribution of the labels\n",
    "    q = np.bincount(y, weights=y_pred_prob) / np.sum(y_pred_prob)\n",
    "    \n",
    "    return q\n",
    "\n",
    "# Train a logistic regression model on the training data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Compute the predicted distribution of the labels using \n",
    "#the logistic regression model\n",
    "q = get_predicted_distribution(X_test, y_test, model)\n",
    "\n",
    "# Compute the KL divergence between the true and predicted distributions\n",
    "#here, the two probability distributions are p(true distribution) and \n",
    "#q(predicted distribution)\n",
    "kl_div = np.sum(np.dot(p , np.log(p / q)))\n",
    "\n",
    "print(\"KL divergence:\", kl_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17722c6b",
   "metadata": {},
   "source": [
    "Here, we firstly get calculated true probability of the target variable \"y\" and predicted probabilities by traing a logistic regression model by splitting X and y into train/test split.\n",
    "\n",
    "Next, we calculate the KL divergence between the two classes using the above defined formula.\n",
    "\n",
    "And, the KL divergence comes out to be 0.53 which shows how similar two classes, p and q are respectively, allowing for comparison and evaluation of these two classes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3107101",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e062ff4",
   "metadata": {},
   "source": [
    "###### link to demonstration video - https://drive.google.com/file/d/1igoj_J3Duv_g0S-5MiHDKw0nuAbX59i4/view?usp=share_link"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
